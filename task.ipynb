{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54ade1c8-8b16-4ea5-84da-4e79eb4f323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# End-to-end implementation for the interview task\n",
    "# - Loads train features + labels (50k rows)\n",
    "# - Aligns/merges safely\n",
    "# - Cleans columns (drops 100% missing + constant cols)\n",
    "# - Builds preprocessing for numeric + categorical\n",
    "# - Trains model (tries LightGBM -> XGBoost -> HistGB fallback)\n",
    "# - Evaluates with PR-AUC, ROC-AUC, LogLoss\n",
    "# - Finds best threshold on validation (max F1 by default)\n",
    "# - Retrains on full data and saves artifacts\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score,\n",
    "    roc_auc_score,\n",
    "    log_loss,\n",
    "    precision_recall_curve,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# -----------------------------\n",
    "# Paths (edit if needed)\n",
    "# -----------------------------\n",
    "FEATURES_PATH = \"train (6).csv\"\n",
    "LABELS_PATH   = \"train_churn_labels.csv\"\n",
    "\n",
    "OUT_DIR = \"model_out\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64950031-8cb3-497d-bd31-6130d2ee7910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f61e18d-3aff-4be1-a5b3-8d9e717fd72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Loading data...\n",
      "2) Cleaning columns...\n",
      "3) Adding missingness features...\n",
      "4) Train/validation split (stratified)...\n",
      "   Positive rate (train): 0.0735 (imbalance expected)\n",
      "5) Model selection...\n",
      "   Using model: lightgbm\n",
      "   scale_pos_weight ~ 12.61\n",
      "6) Hyperparameter search (lightweight)...\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[LightGBM] [Info] Number of positive: 2938, number of negative: 37062\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.111148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23169\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 3751\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "Best CV PR-AUC: 0.2000481371590344\n",
      "Best params: {'model__subsample': 0.9, 'model__reg_lambda': 0.0, 'model__num_leaves': 31, 'model__n_estimators': 1500, 'model__learning_rate': 0.01, 'model__colsample_bytree': 0.9}\n",
      "7) Validation evaluation...\n",
      "   PR-AUC:  0.181010\n",
      "   ROC-AUC: 0.705237\n",
      "   LogLoss: 0.480231\n",
      "   Best threshold (max F1): 0.6064\n",
      "\n",
      "Classification report (val):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9443    0.8954    0.9192      9266\n",
      "           1     0.2018    0.3338    0.2515       734\n",
      "\n",
      "    accuracy                         0.8542     10000\n",
      "   macro avg     0.5731    0.6146    0.5854     10000\n",
      "weighted avg     0.8898    0.8542    0.8702     10000\n",
      "\n",
      "Confusion matrix (val):\n",
      "[[8297  969]\n",
      " [ 489  245]]\n",
      "8) Retrain best model on full data and save artifacts...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 71675 features, but LGBMClassifier is expecting 63722 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 312\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved metadata:\u001b[39m\u001b[38;5;124m\"\u001b[39m, meta_path)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 312\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[4], line 283\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    280\u001b[0m sample_weight_full \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y_full\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, spw_full, \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 283\u001b[0m     best_pipe\u001b[38;5;241m.\u001b[39mfit(X_full, y_full, model__sample_weight\u001b[38;5;241m=\u001b[39msample_weight_full)\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    285\u001b[0m     best_pipe\u001b[38;5;241m.\u001b[39mfit(X_full, y_full)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:473\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    472\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 473\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightgbm\\sklearn.py:1560\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1557\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1558\u001b[0m             valid_sets\u001b[38;5;241m.\u001b[39mappend((valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y)))\n\u001b[1;32m-> 1560\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m   1561\u001b[0m     X,\n\u001b[0;32m   1562\u001b[0m     _y,\n\u001b[0;32m   1563\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1564\u001b[0m     init_score\u001b[38;5;241m=\u001b[39minit_score,\n\u001b[0;32m   1565\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39mvalid_sets,\n\u001b[0;32m   1566\u001b[0m     eval_names\u001b[38;5;241m=\u001b[39meval_names,\n\u001b[0;32m   1567\u001b[0m     eval_sample_weight\u001b[38;5;241m=\u001b[39meval_sample_weight,\n\u001b[0;32m   1568\u001b[0m     eval_class_weight\u001b[38;5;241m=\u001b[39meval_class_weight,\n\u001b[0;32m   1569\u001b[0m     eval_init_score\u001b[38;5;241m=\u001b[39meval_init_score,\n\u001b[0;32m   1570\u001b[0m     eval_metric\u001b[38;5;241m=\u001b[39meval_metric,\n\u001b[0;32m   1571\u001b[0m     feature_name\u001b[38;5;241m=\u001b[39mfeature_name,\n\u001b[0;32m   1572\u001b[0m     categorical_feature\u001b[38;5;241m=\u001b[39mcategorical_feature,\n\u001b[0;32m   1573\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m   1574\u001b[0m     init_model\u001b[38;5;241m=\u001b[39minit_model,\n\u001b[0;32m   1575\u001b[0m )\n\u001b[0;32m   1576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightgbm\\sklearn.py:949\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    946\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [metric \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m metric \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (pd_DataFrame, dt_DataTable)):\n\u001b[1;32m--> 949\u001b[0m     _X, _y \u001b[38;5;241m=\u001b[39m _LGBMValidateData(\n\u001b[0;32m    950\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    951\u001b[0m         X,\n\u001b[0;32m    952\u001b[0m         y,\n\u001b[0;32m    953\u001b[0m         reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    954\u001b[0m         \u001b[38;5;66;03m# allow any input type (this validation is done further down, in lgb.Dataset())\u001b[39;00m\n\u001b[0;32m    955\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    956\u001b[0m         \u001b[38;5;66;03m# do not raise an error if Inf of NaN values are found (LightGBM handles these internally)\u001b[39;00m\n\u001b[0;32m    957\u001b[0m         ensure_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    958\u001b[0m         \u001b[38;5;66;03m# raise an error on 0-row and 1-row inputs\u001b[39;00m\n\u001b[0;32m    959\u001b[0m         ensure_min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    960\u001b[0m     )\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m         sample_weight \u001b[38;5;241m=\u001b[39m _LGBMCheckSampleWeight(sample_weight, _X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightgbm\\compat.py:91\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, accept_sparse, ensure_all_finite, ensure_min_samples, **ignored_kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# raise the same error that scikit-learn's `validate_data()` does on scikit-learn>=1.6\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _estimator\u001b[38;5;241m.\u001b[39m__sklearn_is_fitted__() \u001b[38;5;129;01mand\u001b[39;00m _estimator\u001b[38;5;241m.\u001b[39m_n_features \u001b[38;5;241m!=\u001b[39m n_features_in_:\n\u001b[1;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_estimator\u001b[38;5;241m.\u001b[39m_n_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m     )\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_val_y:\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "\u001b[1;31mValueError\u001b[0m: X has 71675 features, but LGBMClassifier is expecting 63722 features as input."
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Helper classes\n",
    "# -----------------------------\n",
    "class ToDense(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Convert sparse matrix to dense (required for HistGradientBoostingClassifier).\"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.toarray() if hasattr(X, \"toarray\") else np.asarray(X)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Helper functions\n",
    "# -----------------------------\n",
    "def load_and_align(features_path: str, labels_path: str):\n",
    "    X = pd.read_csv(features_path)\n",
    "    y_df = pd.read_csv(labels_path)\n",
    "\n",
    "    possible_label_cols = [\"label\", \"Label\", \"target\", \"Target\", \"y\", \"Y\"]\n",
    "    label_col = None\n",
    "    for c in possible_label_cols:\n",
    "        if c in y_df.columns:\n",
    "            label_col = c\n",
    "            break\n",
    "    if label_col is None:\n",
    "        label_col = y_df.columns[0]\n",
    "\n",
    "    y_raw = y_df[label_col].copy()\n",
    "\n",
    "    if len(X) != len(y_raw):\n",
    "        raise ValueError(f\"Row mismatch: X={len(X)} but y={len(y_raw)}. Need ID-based join.\")\n",
    "\n",
    "    y = y_raw.replace({-1: 0, 1: 1}).astype(int)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def drop_bad_columns(df: pd.DataFrame):\n",
    "    df2 = df.copy()\n",
    "    all_missing = [c for c in df2.columns if df2[c].isna().all()]\n",
    "    df2.drop(columns=all_missing, inplace=True)\n",
    "\n",
    "    constant = [c for c in df2.columns if df2[c].nunique(dropna=True) <= 1]\n",
    "    df2.drop(columns=constant, inplace=True)\n",
    "\n",
    "    dropped = {\"all_missing\": all_missing, \"constant\": constant}\n",
    "    return df2, dropped\n",
    "\n",
    "\n",
    "def add_missingness_features(df: pd.DataFrame):\n",
    "    df2 = df.copy()\n",
    "    miss_count = df2.isna().sum(axis=1)\n",
    "    miss_ratio = miss_count / max(df2.shape[1], 1)\n",
    "    df2[\"__missing_count__\"] = miss_count\n",
    "    df2[\"__missing_ratio__\"] = miss_ratio\n",
    "    return df2\n",
    "\n",
    "\n",
    "def get_feature_types(df: pd.DataFrame):\n",
    "    cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "    num_cols = [c for c in df.columns if c not in cat_cols]\n",
    "    return num_cols, cat_cols\n",
    "\n",
    "\n",
    "def choose_model():\n",
    "    # --- LightGBM ---\n",
    "    try:\n",
    "        from lightgbm import LGBMClassifier\n",
    "        model = LGBMClassifier(\n",
    "            objective=\"binary\",\n",
    "            n_estimators=2000,\n",
    "            learning_rate=0.03,\n",
    "            num_leaves=63,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_lambda=1.0,\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        return \"lightgbm\", model\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # --- XGBoost ---\n",
    "    try:\n",
    "        from xgboost import XGBClassifier\n",
    "        model = XGBClassifier(\n",
    "            n_estimators=1500,\n",
    "            learning_rate=0.03,\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_lambda=1.0,\n",
    "            objective=\"binary:logistic\",\n",
    "            eval_metric=\"logloss\",\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        return \"xgboost\", model\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # --- Fallback: HistGradientBoosting ---\n",
    "    from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "    model = HistGradientBoostingClassifier(\n",
    "        learning_rate=0.06,\n",
    "        max_depth=6,\n",
    "        max_iter=600,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    return \"hist_gb\", model\n",
    "\n",
    "\n",
    "def build_pipeline(X: pd.DataFrame, base_model, model_name: str):\n",
    "    \"\"\"\n",
    "    Key fix:\n",
    "    - HistGradientBoostingClassifier requires dense input.\n",
    "    - So we add ToDense() right after preprocessing only for hist_gb.\n",
    "    \"\"\"\n",
    "    num_cols, cat_cols = get_feature_types(X)\n",
    "\n",
    "    numeric_pipe = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "    ])\n",
    "\n",
    "    categorical_pipe = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_pipe, num_cols),\n",
    "            (\"cat\", categorical_pipe, cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "    steps = [(\"preprocess\", preprocessor)]\n",
    "\n",
    "    if model_name == \"hist_gb\":\n",
    "        steps.append((\"todense\", ToDense()))  # ✅ critical fix\n",
    "\n",
    "    steps.append((\"model\", base_model))\n",
    "\n",
    "    return Pipeline(steps=steps)\n",
    "\n",
    "\n",
    "def find_best_threshold(y_true, y_proba, method=\"max_f1\"):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_proba)\n",
    "    if len(thresholds) == 0:\n",
    "        return 0.5\n",
    "\n",
    "    if method == \"max_f1\":\n",
    "        f1s = (2 * precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-12)\n",
    "        best_idx = int(np.argmax(f1s))\n",
    "        return float(thresholds[best_idx])\n",
    "\n",
    "    return 0.5\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Main training flow\n",
    "# -----------------------------\n",
    "def main():\n",
    "    print(\"1) Loading data...\")\n",
    "    X_raw, y = load_and_align(FEATURES_PATH, LABELS_PATH)\n",
    "\n",
    "    print(\"2) Cleaning columns...\")\n",
    "    X_clean, dropped = drop_bad_columns(X_raw)\n",
    "\n",
    "    print(\"3) Adding missingness features...\")\n",
    "    X_feat = add_missingness_features(X_clean)\n",
    "\n",
    "    print(\"4) Train/validation split (stratified)...\")\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_feat, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "\n",
    "    pos_rate = y_train.mean()\n",
    "    print(f\"   Positive rate (train): {pos_rate:.4f} (imbalance expected)\")\n",
    "\n",
    "    print(\"5) Model selection...\")\n",
    "    model_name, base_model = choose_model()\n",
    "    print(f\"   Using model: {model_name}\")\n",
    "\n",
    "    neg = int((y_train == 0).sum())\n",
    "    pos = int((y_train == 1).sum())\n",
    "    if pos == 0:\n",
    "        raise ValueError(\"No positive samples in training split.\")\n",
    "    scale_pos_weight = neg / pos\n",
    "    print(f\"   scale_pos_weight ~ {scale_pos_weight:.2f}\")\n",
    "\n",
    "    pipe = build_pipeline(X_train, base_model, model_name)\n",
    "\n",
    "    print(\"6) Hyperparameter search (lightweight)...\")\n",
    "    if model_name == \"lightgbm\":\n",
    "        param_dist = {\n",
    "            \"model__num_leaves\": [31, 63, 127],\n",
    "            \"model__learning_rate\": [0.01, 0.03, 0.06],\n",
    "            \"model__n_estimators\": [800, 1500, 2500],\n",
    "            \"model__subsample\": [0.7, 0.8, 0.9],\n",
    "            \"model__colsample_bytree\": [0.7, 0.8, 0.9],\n",
    "            \"model__reg_lambda\": [0.0, 1.0, 5.0],\n",
    "        }\n",
    "    elif model_name == \"xgboost\":\n",
    "        param_dist = {\n",
    "            \"model__max_depth\": [4, 6, 8],\n",
    "            \"model__learning_rate\": [0.01, 0.03, 0.06],\n",
    "            \"model__n_estimators\": [800, 1500, 2500],\n",
    "            \"model__subsample\": [0.7, 0.8, 0.9],\n",
    "            \"model__colsample_bytree\": [0.7, 0.8, 0.9],\n",
    "            \"model__reg_lambda\": [0.0, 1.0, 5.0],\n",
    "        }\n",
    "    else:\n",
    "        param_dist = {\n",
    "            \"model__learning_rate\": [0.03, 0.06, 0.1],\n",
    "            \"model__max_depth\": [4, 6, 8],\n",
    "            \"model__max_iter\": [300, 600, 900],\n",
    "        }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=min(15, sum(len(v) for v in param_dist.values())),\n",
    "        scoring=\"average_precision\",\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        error_score=\"raise\"   # ✅ so you see the REAL root error immediately\n",
    "    )\n",
    "\n",
    "    # sample weights (try to pass them; if estimator doesn't support, fall back)\n",
    "    sample_weight = np.where(y_train.values == 1, scale_pos_weight, 1.0)\n",
    "\n",
    "    try:\n",
    "        search.fit(X_train, y_train, model__sample_weight=sample_weight)\n",
    "    except TypeError:\n",
    "        search.fit(X_train, y_train)\n",
    "\n",
    "    best_pipe = search.best_estimator_\n",
    "    print(\"Best CV PR-AUC:\", search.best_score_)\n",
    "    print(\"Best params:\", search.best_params_)\n",
    "\n",
    "    print(\"7) Validation evaluation...\")\n",
    "    if hasattr(best_pipe, \"predict_proba\"):\n",
    "        y_val_proba = best_pipe.predict_proba(X_val)[:, 1]\n",
    "    else:\n",
    "        # fallback; most should have predict_proba\n",
    "        y_val_proba = best_pipe.predict(X_val)\n",
    "\n",
    "    pr_auc = average_precision_score(y_val, y_val_proba)\n",
    "    roc_auc = roc_auc_score(y_val, y_val_proba)\n",
    "    ll = log_loss(y_val, y_val_proba)\n",
    "\n",
    "    print(f\"   PR-AUC:  {pr_auc:.6f}\")\n",
    "    print(f\"   ROC-AUC: {roc_auc:.6f}\")\n",
    "    print(f\"   LogLoss: {ll:.6f}\")\n",
    "\n",
    "    thr = find_best_threshold(y_val, y_val_proba, method=\"max_f1\")\n",
    "    print(f\"   Best threshold (max F1): {thr:.4f}\")\n",
    "\n",
    "    y_val_pred = (y_val_proba >= thr).astype(int)\n",
    "\n",
    "    print(\"\\nClassification report (val):\")\n",
    "    print(classification_report(y_val, y_val_pred, digits=4))\n",
    "    print(\"Confusion matrix (val):\")\n",
    "    print(confusion_matrix(y_val, y_val_pred))\n",
    "\n",
    "    print(\"8) Retrain best model on full data and save artifacts...\")\n",
    "    X_full = X_feat\n",
    "    y_full = y\n",
    "\n",
    "    neg_full = int((y_full == 0).sum())\n",
    "    pos_full = int((y_full == 1).sum())\n",
    "    spw_full = neg_full / max(pos_full, 1)\n",
    "    sample_weight_full = np.where(y_full.values == 1, spw_full, 1.0)\n",
    "\n",
    "    try:\n",
    "        best_pipe.fit(X_full, y_full, model__sample_weight=sample_weight_full)\n",
    "    except TypeError:\n",
    "        best_pipe.fit(X_full, y_full)\n",
    "\n",
    "    model_path = os.path.join(OUT_DIR, f\"final_model_{model_name}.joblib\")\n",
    "    joblib.dump(best_pipe, model_path)\n",
    "\n",
    "    meta = {\n",
    "        \"model_name\": model_name,\n",
    "        \"dropped_columns\": dropped,\n",
    "        \"best_params\": search.best_params_,\n",
    "        \"val_metrics\": {\n",
    "            \"pr_auc\": float(pr_auc),\n",
    "            \"roc_auc\": float(roc_auc),\n",
    "            \"log_loss\": float(ll),\n",
    "            \"threshold_max_f1\": float(thr)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    meta_path = os.path.join(OUT_DIR, \"training_metadata.json\")\n",
    "    with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "\n",
    "    print(\"\\nDONE ✅\")\n",
    "    print(\"Saved model:\", model_path)\n",
    "    print(\"Saved metadata:\", meta_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daf66473-758a-426c-ac38-d9294d06b696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "PHASE 1 — BUSINESS UNDERSTANDING\n",
      "=================================================================\n",
      "\n",
      "Objective : Predict customer churn (binary classification).\n",
      "           Label  1 -> churned customer\n",
      "           Label -1 -> retained customer\n",
      "Business Metric : Maximize recall on churners (avoid missed\n",
      "                  churners) while keeping precision reasonable.\n",
      "                  Primary metric: ROC-AUC + F1-churn.\n",
      "Success Criteria: ROC-AUC > 0.75 | F1 (churn class) > 0.40\n",
      "\n",
      "=================================================================\n",
      "PHASE 2 — DATA UNDERSTANDING\n",
      "=================================================================\n",
      "Dataset shape     : (50000, 230)\n",
      "Labels shape      : (50000, 1)\n",
      "Class distribution: Retained(0)=46328  Churned(1)=3672\n",
      "Churn rate        : 7.34%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "=============================================================\n",
    "CRISP-DM Machine Learning Pipeline — Customer Churn Prediction\n",
    "=============================================================\n",
    "HOW TO RUN:\n",
    "  pip install pandas numpy matplotlib seaborn scikit-learn\n",
    "  python crisp_dm_pipeline.py\n",
    "\n",
    "INPUT FILES (same folder as script):\n",
    "  - train__6_.csv\n",
    "  - train_churn_labels.csv\n",
    "\n",
    "OUTPUT FILES:\n",
    "  - crisp_dm_results.png\n",
    "  - best_model.pkl\n",
    "  - model_metadata.json\n",
    "  - crisp_dm_report.txt\n",
    "  - validation_predictions.csv\n",
    "=============================================================\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json, time, pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    roc_curve, precision_recall_curve, average_precision_score,\n",
    "    f1_score, precision_score, recall_score\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "REPORT_LINES = []\n",
    "\n",
    "def log(msg=\"\"):\n",
    "    print(msg)\n",
    "    REPORT_LINES.append(str(msg))\n",
    "\n",
    "# =============================================================\n",
    "# PHASE 1 — BUSINESS UNDERSTANDING\n",
    "# =============================================================\n",
    "log(\"=\" * 65)\n",
    "log(\"PHASE 1 — BUSINESS UNDERSTANDING\")\n",
    "log(\"=\" * 65)\n",
    "log(\"\"\"\n",
    "Objective : Predict customer churn (binary classification).\n",
    "           Label  1 -> churned customer\n",
    "           Label -1 -> retained customer\n",
    "Business Metric : Maximize recall on churners (avoid missed\n",
    "                  churners) while keeping precision reasonable.\n",
    "                  Primary metric: ROC-AUC + F1-churn.\n",
    "Success Criteria: ROC-AUC > 0.75 | F1 (churn class) > 0.40\n",
    "\"\"\")\n",
    "\n",
    "# =============================================================\n",
    "# PHASE 2 — DATA UNDERSTANDING\n",
    "# =============================================================\n",
    "log(\"=\" * 65)\n",
    "log(\"PHASE 2 — DATA UNDERSTANDING\")\n",
    "log(\"=\" * 65)\n",
    "\n",
    "\n",
    "df  = pd.read_csv(\"train (6).csv\", low_memory=False)\n",
    "labels = pd.read_csv(\"train_churn_labels.csv\")\n",
    "\n",
    "log(f\"Dataset shape     : {df.shape}\")\n",
    "log(f\"Labels shape      : {labels.shape}\")\n",
    "\n",
    "y = labels[\"Label\"].map({-1: 0, 1: 1}).values\n",
    "log(f\"Class distribution: Retained(0)={int((y==0).sum())}  Churned(1)={int((y==1).sum())}\")\n",
    "log(f\"Churn rate        : {y.mean()*100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f02c73b4-02fb-4994-8a7e-d7a0eebf52ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features  : 192\n",
      "Categorical feats : 38\n",
      "Overall missing % : 69.8%\n",
      "Cols > 80% missing: 154\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols     = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "log(f\"Numeric features  : {len(numeric_cols)}\")\n",
    "log(f\"Categorical feats : {len(cat_cols)}\")\n",
    "log(f\"Overall missing % : {df.isnull().mean().mean()*100:.1f}%\")\n",
    "\n",
    "miss_pct  = df.isnull().mean() * 100\n",
    "high_miss = miss_pct[miss_pct > 80]\n",
    "log(f\"Cols > 80% missing: {len(high_miss)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7187fd4-525b-4940-b420-81c1ba14e654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "PHASE 3 — DATA PREPARATION\n",
      "=================================================================\n",
      "Dropped 154 high-missing columns. Remaining: 76\n",
      "Dropped 14 high-cardinality cat cols. Remaining: 62\n",
      "Final numeric: 42, categorical: 20\n",
      "Train size: 40000 | Val size: 10000\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# PHASE 3 — DATA PREPARATION\n",
    "# =============================================================\n",
    "log(\"\\n\" + \"=\" * 65)\n",
    "log(\"PHASE 3 — DATA PREPARATION\")\n",
    "log(\"=\" * 65)\n",
    "\n",
    "orig_df  = df.copy()\n",
    "df_clean = df.copy()\n",
    "\n",
    "drop_cols = high_miss.index.tolist()\n",
    "df_clean.drop(columns=drop_cols, inplace=True)\n",
    "log(f\"Dropped {len(drop_cols)} high-missing columns. Remaining: {df_clean.shape[1]}\")\n",
    "\n",
    "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols     = df_clean.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "useful_cat = [c for c in cat_cols if df_clean[c].nunique() < 50]\n",
    "drop_cat   = [c for c in cat_cols if c not in useful_cat]\n",
    "df_clean.drop(columns=drop_cat, inplace=True)\n",
    "log(f\"Dropped {len(drop_cat)} high-cardinality cat cols. Remaining: {df_clean.shape[1]}\")\n",
    "\n",
    "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols     = df_clean.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "log(f\"Final numeric: {len(numeric_cols)}, categorical: {len(cat_cols)}\")\n",
    "\n",
    "le = LabelEncoder()\n",
    "for c in cat_cols:\n",
    "    df_clean[c] = df_clean[c].fillna(\"__missing__\")\n",
    "    df_clean[c] = le.fit_transform(df_clean[c].astype(str))\n",
    "\n",
    "all_feat_cols = numeric_cols + cat_cols\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\",  StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_pipe,                               numeric_cols),\n",
    "    (\"cat\", SimpleImputer(strategy=\"most_frequent\"), cat_cols)\n",
    "])\n",
    "\n",
    "X = df_clean[all_feat_cols]\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "log(f\"Train size: {len(X_train)} | Val size: {len(X_val)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02b04a95-cb61-45da-8f7f-b360ca7b1c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "PHASE 4 — MODELING\n",
      "=================================================================\n",
      "\n",
      "  Training: Baseline (Majority) ...\n",
      "    ROC-AUC=0.5000  AP=0.0000  F1-Churn=0.0000  [0.0s]\n",
      "\n",
      "  Training: Logistic Regression ...\n",
      "    ROC-AUC=0.6718  AP=0.1379  F1-Churn=0.1968  [2.9s]\n",
      "\n",
      "  Training: Random Forest ...\n",
      "    ROC-AUC=0.7003  AP=0.1578  F1-Churn=0.2291  [3.7s]\n",
      "\n",
      "  Training: Gradient Boosting ...\n",
      "    ROC-AUC=0.7158  AP=0.1936  F1-Churn=0.0266  [81.6s]\n",
      "\n",
      "  Training: RF Balanced Subsample ...\n",
      "    ROC-AUC=0.6977  AP=0.1524  F1-Churn=0.2294  [5.5s]\n",
      "\n",
      "  Best model: Gradient Boosting  (ROC-AUC=0.7158)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# PHASE 4 — MODELING\n",
    "# =============================================================\n",
    "log(\"\\n\" + \"=\" * 65)\n",
    "log(\"PHASE 4 — MODELING\")\n",
    "log(\"=\" * 65)\n",
    "\n",
    "def make_pipeline(clf):\n",
    "    return Pipeline([(\"prep\", preprocessor), (\"clf\", clf)])\n",
    "\n",
    "models = {\n",
    "    \"Baseline (Majority)\"   : DummyClassifier(strategy=\"most_frequent\"),\n",
    "    \"Logistic Regression\"   : make_pipeline(\n",
    "        LogisticRegression(max_iter=1000, C=0.1, class_weight=\"balanced\", random_state=42)\n",
    "    ),\n",
    "    \"Random Forest\"         : make_pipeline(\n",
    "        RandomForestClassifier(n_estimators=200, max_depth=8,\n",
    "                               class_weight=\"balanced\", random_state=42, n_jobs=-1)\n",
    "    ),\n",
    "    \"Gradient Boosting\"     : make_pipeline(\n",
    "        GradientBoostingClassifier(n_estimators=150, max_depth=4,\n",
    "                                   learning_rate=0.05, random_state=42)\n",
    "    ),\n",
    "    \"RF Balanced Subsample\" : make_pipeline(\n",
    "        RandomForestClassifier(n_estimators=200, max_depth=10,\n",
    "                               class_weight=\"balanced_subsample\", random_state=1, n_jobs=-1)\n",
    "    ),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    t0 = time.time()\n",
    "    log(f\"\\n  Training: {name} ...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_prob = np.zeros(len(y_val)) if name == \"Baseline (Majority)\" else model.predict_proba(X_val)[:, 1]\n",
    "    auc     = roc_auc_score(y_val, y_prob) if y_prob.sum() > 0 else 0.5\n",
    "    ap      = average_precision_score(y_val, y_prob) if y_prob.sum() > 0 else 0\n",
    "    f1c     = f1_score(y_val, y_pred, pos_label=1, zero_division=0)\n",
    "    elapsed = time.time() - t0\n",
    "    results[name] = {\"model\": model, \"y_pred\": y_pred, \"y_prob\": y_prob,\n",
    "                     \"auc\": auc, \"ap\": ap, \"f1_churn\": f1c, \"time\": elapsed}\n",
    "    log(f\"    ROC-AUC={auc:.4f}  AP={ap:.4f}  F1-Churn={f1c:.4f}  [{elapsed:.1f}s]\")\n",
    "\n",
    "best_name = max([k for k in results if k != \"Baseline (Majority)\"],\n",
    "                key=lambda k: results[k][\"auc\"])\n",
    "log(f\"\\n  Best model: {best_name}  (ROC-AUC={results[best_name]['auc']:.4f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cc4f10e-b0ee-4a8d-b02f-d7817d69efd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "PHASE 5 — EVALUATION\n",
      "=================================================================\n",
      "\n",
      "Classification Report — Gradient Boosting\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Retained       0.93      1.00      0.96      9266\n",
      "     Churned       0.59      0.01      0.03       734\n",
      "\n",
      "    accuracy                           0.93     10000\n",
      "   macro avg       0.76      0.51      0.49     10000\n",
      "weighted avg       0.90      0.93      0.89     10000\n",
      "\n",
      "\n",
      "Optimal decision threshold (max F1): 0.12\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# PHASE 5 — EVALUATION\n",
    "# =============================================================\n",
    "log(\"\\n\" + \"=\" * 65)\n",
    "log(\"PHASE 5 — EVALUATION\")\n",
    "log(\"=\" * 65)\n",
    "\n",
    "best = results[best_name]\n",
    "log(\"\\nClassification Report — \" + best_name)\n",
    "log(classification_report(y_val, best[\"y_pred\"], target_names=[\"Retained\", \"Churned\"]))\n",
    "\n",
    "probs      = best[\"y_prob\"]\n",
    "thresholds = np.linspace(0.1, 0.9, 80)\n",
    "f1s_thresh, recalls_t, precisions_t = [], [], []\n",
    "for t in thresholds:\n",
    "    yp = (probs >= t).astype(int)\n",
    "    f1s_thresh.append(f1_score(y_val, yp, pos_label=1, zero_division=0))\n",
    "    recalls_t.append(recall_score(y_val, yp, pos_label=1, zero_division=0))\n",
    "    precisions_t.append(precision_score(y_val, yp, pos_label=1, zero_division=0))\n",
    "best_t_idx     = int(np.argmax(f1s_thresh))\n",
    "best_threshold = float(thresholds[best_t_idx])\n",
    "log(f\"\\nOptimal decision threshold (max F1): {best_threshold:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "808e406e-2d9e-4415-bcfe-c7c8f3abd65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: crisp_dm_results.png\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# VISUALISATIONS — 10 panels\n",
    "# =============================================================\n",
    "PALETTE = [\"#2196F3\", \"#4CAF50\", \"#FF9800\", \"#E91E63\", \"#9C27B0\"]\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fig = plt.figure(figsize=(20, 24))\n",
    "fig.suptitle(\"CRISP-DM Churn Prediction Pipeline — Results\",\n",
    "             fontsize=16, fontweight=\"bold\", y=0.98)\n",
    "gs = gridspec.GridSpec(4, 3, figure=fig, hspace=0.45, wspace=0.35)\n",
    "\n",
    "# Panel 1: Class Distribution\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "class_counts = pd.Series(y).value_counts().sort_index()\n",
    "bars = ax1.bar([\"Retained (0)\", \"Churned (1)\"], class_counts.values,\n",
    "               color=[\"#4CAF50\", \"#E91E63\"], edgecolor=\"white\", linewidth=1.5)\n",
    "for bar, v in zip(bars, class_counts.values):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height()+300,\n",
    "             f\"{v:,}\\n({v/len(y)*100:.1f}%)\", ha=\"center\", fontsize=10, fontweight=\"bold\")\n",
    "ax1.set_title(\"Class Distribution\", fontweight=\"bold\")\n",
    "ax1.set_ylabel(\"Count\")\n",
    "ax1.set_ylim(0, class_counts.max() * 1.2)\n",
    "\n",
    "# Panel 2: Missingness Distribution\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "miss_bins   = pd.cut(orig_df.isnull().mean()*100, bins=[0,20,40,60,80,100],\n",
    "                     labels=[\"0-20%\",\"20-40%\",\"40-60%\",\"60-80%\",\"80-100%\"])\n",
    "miss_counts = miss_bins.value_counts().sort_index()\n",
    "ax2.bar(miss_counts.index, miss_counts.values, color=PALETTE, edgecolor=\"white\")\n",
    "ax2.set_title(\"Feature Missingness Distribution\", fontweight=\"bold\")\n",
    "ax2.set_xlabel(\"Missing %\"); ax2.set_ylabel(\"# Features\")\n",
    "\n",
    "# Panel 3: Model Comparison\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "mnames = list(results.keys())\n",
    "aucs = [results[m][\"auc\"] for m in mnames]\n",
    "f1s  = [results[m][\"f1_churn\"] for m in mnames]\n",
    "x, w = np.arange(len(mnames)), 0.35\n",
    "ax3.bar(x-w/2, aucs, w, label=\"ROC-AUC\",  color=\"#2196F3\", alpha=0.85)\n",
    "ax3.bar(x+w/2, f1s,  w, label=\"F1-Churn\", color=\"#E91E63\", alpha=0.85)\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels([m.replace(\" \",\"\\n\") for m in mnames], fontsize=7)\n",
    "ax3.axhline(0.5, ls=\"--\", color=\"gray\", alpha=0.5)\n",
    "ax3.set_ylim(0, 1.05); ax3.set_title(\"Model Comparison\", fontweight=\"bold\")\n",
    "ax3.legend(fontsize=8); ax3.set_ylabel(\"Score\")\n",
    "\n",
    "# Panel 4: ROC Curves\n",
    "ax4 = fig.add_subplot(gs[1, 0:2])\n",
    "for i, (name, res) in enumerate(results.items()):\n",
    "    if name == \"Baseline (Majority)\": continue\n",
    "    fpr, tpr, _ = roc_curve(y_val, res[\"y_prob\"])\n",
    "    ax4.plot(fpr, tpr, lw=2, color=PALETTE[i%len(PALETTE)],\n",
    "             label=f\"{name} (AUC={res['auc']:.3f})\")\n",
    "ax4.plot([0,1],[0,1],\"k--\",alpha=0.4)\n",
    "fpr_b, tpr_b, _ = roc_curve(y_val, best[\"y_prob\"])\n",
    "ax4.fill_between(fpr_b, tpr_b, alpha=0.08, color=PALETTE[0])\n",
    "ax4.set_xlabel(\"False Positive Rate\"); ax4.set_ylabel(\"True Positive Rate\")\n",
    "ax4.set_title(\"ROC Curves — All Models\", fontweight=\"bold\")\n",
    "ax4.legend(fontsize=8, loc=\"lower right\")\n",
    "ax4.set_xlim([0,1]); ax4.set_ylim([0,1])\n",
    "\n",
    "# Panel 5: Precision-Recall\n",
    "ax5 = fig.add_subplot(gs[1, 2])\n",
    "for i, (name, res) in enumerate(results.items()):\n",
    "    if name == \"Baseline (Majority)\": continue\n",
    "    prec, rec, _ = precision_recall_curve(y_val, res[\"y_prob\"])\n",
    "    ax5.plot(rec, prec, lw=1.8, color=PALETTE[i%len(PALETTE)],\n",
    "             label=f\"{name[:12]} (AP={res['ap']:.3f})\")\n",
    "ax5.axhline(y.mean(), ls=\"--\", color=\"gray\", alpha=0.5, label=\"Baseline\")\n",
    "ax5.set_xlabel(\"Recall\"); ax5.set_ylabel(\"Precision\")\n",
    "ax5.set_title(\"Precision-Recall Curves\", fontweight=\"bold\")\n",
    "ax5.legend(fontsize=6.5, loc=\"upper right\")\n",
    "\n",
    "# Panel 6: Confusion Matrix\n",
    "ax6 = fig.add_subplot(gs[2, 0])\n",
    "cm = confusion_matrix(y_val, best[\"y_pred\"])\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Retained\",\"Churned\"],\n",
    "            yticklabels=[\"Retained\",\"Churned\"], ax=ax6,\n",
    "            annot_kws={\"size\":13,\"weight\":\"bold\"})\n",
    "ax6.set_title(f\"Confusion Matrix\\n{best_name}\", fontweight=\"bold\")\n",
    "ax6.set_ylabel(\"Actual\"); ax6.set_xlabel(\"Predicted\")\n",
    "\n",
    "# Panel 7: Feature Importances\n",
    "ax7 = fig.add_subplot(gs[2, 1:])\n",
    "try:\n",
    "    clf_step = best[\"model\"].named_steps[\"clf\"]\n",
    "    if hasattr(clf_step, \"feature_importances_\"):\n",
    "        imp = clf_step.feature_importances_\n",
    "        feat_names = ([f\"num_{c}\" for c in numeric_cols] +\n",
    "                      [f\"cat_{c}\" for c in cat_cols])\n",
    "        if len(imp) == len(feat_names):\n",
    "            fi_df = pd.DataFrame({\"feature\": feat_names, \"importance\": imp})\n",
    "            fi_df = fi_df.nlargest(20, \"importance\")\n",
    "            ax7.barh(fi_df[\"feature\"], fi_df[\"importance\"], color=\"#2196F3\", alpha=0.8)\n",
    "            ax7.set_xlabel(\"Importance\")\n",
    "            ax7.set_title(f\"Top-20 Feature Importances\\n{best_name}\", fontweight=\"bold\")\n",
    "            ax7.invert_yaxis()\n",
    "        else:\n",
    "            ax7.text(0.5, 0.5, \"Feature count mismatch\", ha=\"center\", transform=ax7.transAxes)\n",
    "    else:\n",
    "        ax7.text(0.5, 0.5, \"Feature importance not available\", ha=\"center\",\n",
    "                 va=\"center\", transform=ax7.transAxes, fontsize=11)\n",
    "        ax7.set_title(\"Feature Importances\", fontweight=\"bold\")\n",
    "except Exception as e:\n",
    "    ax7.text(0.5, 0.5, f\"Could not compute importances:\\n{e}\",\n",
    "             ha=\"center\", va=\"center\", transform=ax7.transAxes, fontsize=9)\n",
    "\n",
    "# Panel 8: Score Distribution\n",
    "ax8 = fig.add_subplot(gs[3, 0])\n",
    "ax8.hist(probs[y_val==0], bins=40, alpha=0.6, color=\"#4CAF50\", label=\"Retained\", density=True)\n",
    "ax8.hist(probs[y_val==1], bins=40, alpha=0.6, color=\"#E91E63\", label=\"Churned\",  density=True)\n",
    "ax8.axvline(0.5, ls=\"--\", color=\"black\", alpha=0.6, label=\"Default threshold\")\n",
    "ax8.set_xlabel(\"Predicted Churn Probability\"); ax8.set_ylabel(\"Density\")\n",
    "ax8.set_title(\"Score Distribution by Class\", fontweight=\"bold\")\n",
    "ax8.legend()\n",
    "\n",
    "# Panel 9: Threshold Tuning\n",
    "ax9 = fig.add_subplot(gs[3, 1])\n",
    "ax9.plot(thresholds, f1s_thresh,   color=\"#2196F3\", lw=2, label=\"F1\")\n",
    "ax9.plot(thresholds, recalls_t,    color=\"#4CAF50\", lw=2, label=\"Recall\")\n",
    "ax9.plot(thresholds, precisions_t, color=\"#E91E63\", lw=2, label=\"Precision\")\n",
    "ax9.axvline(best_threshold, ls=\"--\", color=\"black\",\n",
    "            label=f\"Best thresh={best_threshold:.2f}\")\n",
    "ax9.set_xlabel(\"Decision Threshold\"); ax9.set_ylabel(\"Score\")\n",
    "ax9.set_title(\"Threshold Tuning\", fontweight=\"bold\")\n",
    "ax9.legend(fontsize=8)\n",
    "\n",
    "# Panel 10: Leaderboard Table\n",
    "ax10 = fig.add_subplot(gs[3, 2])\n",
    "ax10.axis(\"off\")\n",
    "table_data = [\n",
    "    [name[:22], f\"{res['auc']:.4f}\", f\"{res['ap']:.4f}\",\n",
    "     f\"{res['f1_churn']:.4f}\", f\"{res['time']:.1f}s\"]\n",
    "    for name, res in results.items()\n",
    "]\n",
    "tbl = ax10.table(cellText=table_data,\n",
    "                 colLabels=[\"Model\",\"ROC-AUC\",\"Avg Prec\",\"F1-Churn\",\"Time\"],\n",
    "                 loc=\"center\", cellLoc=\"center\")\n",
    "tbl.auto_set_font_size(False); tbl.set_fontsize(7.5); tbl.scale(1.1, 1.6)\n",
    "for (r, c), cell in tbl.get_celld().items():\n",
    "    if r == 0:\n",
    "        cell.set_facecolor(\"#2196F3\")\n",
    "        cell.set_text_props(color=\"white\", fontweight=\"bold\")\n",
    "    elif r > 0 and table_data[r-1][0].strip() == best_name[:22].strip():\n",
    "        cell.set_facecolor(\"#E8F5E9\")\n",
    "ax10.set_title(\"Model Leaderboard\", fontweight=\"bold\", pad=12)\n",
    "\n",
    "plt.savefig(\"crisp_dm_results.png\", dpi=150, bbox_inches=\"tight\", facecolor=\"white\")\n",
    "plt.close()\n",
    "log(\"  Saved: crisp_dm_results.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9617d28c-efde-4a7e-8c55-6d2e361bac54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "PHASE 6 — DEPLOYMENT\n",
      "=================================================================\n",
      "  Saved: best_model.pkl\n",
      "  Saved: model_metadata.json\n",
      "  Saved: crisp_dm_report.txt\n",
      "  Saved: validation_predictions.csv\n",
      "\n",
      "=================================================================\n",
      "PIPELINE COMPLETE\n",
      "  Best Model    : Gradient Boosting\n",
      "  ROC-AUC       : 0.7158\n",
      "  F1-Churn      : 0.0266\n",
      "  Opt Threshold : 0.12\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# PHASE 6 — DEPLOYMENT ARTIFACTS\n",
    "# =============================================================\n",
    "log(\"\\n\" + \"=\" * 65)\n",
    "log(\"PHASE 6 — DEPLOYMENT\")\n",
    "log(\"=\" * 65)\n",
    "\n",
    "with open(\"best_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best[\"model\"], f)\n",
    "log(\"  Saved: best_model.pkl\")\n",
    "\n",
    "metadata = {\n",
    "    \"best_model\"        : best_name,\n",
    "    \"roc_auc\"           : round(float(best[\"auc\"]), 4),\n",
    "    \"avg_precision\"     : round(float(best[\"ap\"]), 4),\n",
    "    \"f1_churn\"          : round(float(best[\"f1_churn\"]), 4),\n",
    "    \"optimal_threshold\" : round(best_threshold, 4),\n",
    "    \"features_used\"     : all_feat_cols,\n",
    "    \"n_features\"        : len(all_feat_cols),\n",
    "    \"train_size\"        : int(len(X_train)),\n",
    "    \"val_size\"          : int(len(X_val)),\n",
    "    \"class_distribution\": {\"retained\": int((y==0).sum()), \"churned\": int((y==1).sum())},\n",
    "    \"churn_rate_pct\"    : round(float(y.mean()*100), 2)\n",
    "}\n",
    "with open(\"model_metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "log(\"  Saved: model_metadata.json\")\n",
    "\n",
    "with open(\"crisp_dm_report.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(REPORT_LINES))\n",
    "log(\"  Saved: crisp_dm_report.txt\")\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"churn_probability\": best[\"y_prob\"],\n",
    "    \"predicted_label\"  : (best[\"y_prob\"] >= best_threshold).astype(int),\n",
    "    \"actual_label\"     : y_val\n",
    "})\n",
    "pred_df.to_csv(\"validation_predictions.csv\", index=False)\n",
    "log(\"  Saved: validation_predictions.csv\")\n",
    "\n",
    "log(\"\\n\" + \"=\" * 65)\n",
    "log(\"PIPELINE COMPLETE\")\n",
    "log(f\"  Best Model    : {best_name}\")\n",
    "log(f\"  ROC-AUC       : {best['auc']:.4f}\")\n",
    "log(f\"  F1-Churn      : {best['f1_churn']:.4f}\")\n",
    "log(f\"  Opt Threshold : {best_threshold:.2f}\")\n",
    "log(\"=\" * 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aebb00-c1ca-49a6-bfc3-2f7a872bf1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
